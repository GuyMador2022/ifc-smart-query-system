#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ğŸ“Š IFC Query Logger
××¢×¨×›×ª ×œ×•×’×™× ××ª×§×“××ª ×œ×ª×™×¢×•×“ ×©××œ×•×ª ××©×ª××©×™×
"""

import json
import csv
import os
from datetime import datetime
from typing import Dict, List, Any, Optional
import logging
from dataclasses import dataclass, asdict
from pathlib import Path

@dataclass
class UserQuery:
    """××‘× ×” × ×ª×•× ×™× ×œ×©××œ×ª ××©×ª××©"""
    timestamp: str
    session_id: str
    user_question: str
    profession: Optional[str]  # ××“×¨×™×›×œ/××”× ×“×¡/×‘×¢×œ ×¤×¨×•×™×§×˜
    category: Optional[str]    # ×”×§×˜×’×•×¨×™×” ×”×¡×¤×¦×™×¤×™×ª
    query_type: str           # "predefined", "ai_translation", "manual_sql", "free_chat"
    sql_query: Optional[str]
    success: bool
    execution_time_ms: Optional[float]
    result_rows: Optional[int]
    error_message: Optional[str]
    ai_translation_used: bool
    user_agent: Optional[str]
    ip_address: Optional[str]

class IFCQueryLogger:
    """××—×œ×§×” ×œ× ×™×”×•×œ ×œ×•×’×™× ×©×œ ×©××œ×•×ª ××©×ª××©×™×"""
    
    def __init__(self, log_dir: str = "logs"):
        self.log_dir = Path(log_dir)
        self.log_dir.mkdir(exist_ok=True)
        
        # ×§×‘×¦×™ ×œ×•×’ ×©×•× ×™×
        self.json_log_file = self.log_dir / "user_queries.jsonl"
        self.csv_log_file = self.log_dir / "user_queries.csv"
        self.daily_log_file = self.log_dir / f"queries_{datetime.now().strftime('%Y%m%d')}.log"
        
        # ×”×’×“×¨×ª logger ×¨×’×™×œ
        self.setup_logging()
        
        # ××ª×—×•×œ ×§×•×‘×¥ CSV ×× ×œ× ×§×™×™×
        self.init_csv_file()
        
    def setup_logging(self):
        """×”×’×“×¨×ª ××¢×¨×›×ª ×”×œ×•×’×™× ×”×¨×’×™×œ×”"""
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler(self.daily_log_file, encoding='utf-8'),
                logging.StreamHandler()
            ]
        )
        self.logger = logging.getLogger(__name__)
        
    def init_csv_file(self):
        """××ª×—×•×œ ×§×•×‘×¥ CSV ×¢× ×›×•×ª×¨×•×ª"""
        if not self.csv_log_file.exists():
            headers = [
                'timestamp', 'session_id', 'user_question', 'profession', 'category',
                'query_type', 'sql_query', 'success', 'execution_time_ms', 
                'result_rows', 'error_message', 'ai_translation_used'
            ]
            
            with open(self.csv_log_file, 'w', newline='', encoding='utf-8') as f:
                writer = csv.writer(f)
                writer.writerow(headers)
                
    def log_query(self, query: UserQuery):
        """×¨×™×©×•× ×©××œ×” ×‘××¢×¨×›×ª ×”×œ×•×’×™×"""
        try:
            # ×¨×™×©×•× ×‘-JSON Lines
            self._log_to_jsonl(query)
            
            # ×¨×™×©×•× ×‘-CSV
            self._log_to_csv(query)
            
            # ×¨×™×©×•× ×‘×œ×•×’ ×¨×’×™×œ
            self._log_to_standard(query)
            
            print(f"âœ… × ×¨×©× ×‘×œ×•×’: {query.user_question[:50]}...")
            
        except Exception as e:
            self.logger.error(f"×©×’×™××” ×‘×¨×™×©×•× ×œ×•×’: {e}")
            
    def _log_to_jsonl(self, query: UserQuery):
        """×¨×™×©×•× ×‘-JSON Lines (×§×œ ×œ×¢×™×‘×•×“ ××•×˜×•××˜×™)"""
        with open(self.json_log_file, 'a', encoding='utf-8') as f:
            json.dump(asdict(query), f, ensure_ascii=False)
            f.write('\n')
            
    def _log_to_csv(self, query: UserQuery):
        """×¨×™×©×•× ×‘-CSV (×§×œ ×œ×¢×™×‘×•×“ ×‘-Excel)"""
        with open(self.csv_log_file, 'a', newline='', encoding='utf-8') as f:
            writer = csv.writer(f)
            row = [
                query.timestamp, query.session_id, query.user_question,
                query.profession, query.category, query.query_type,
                query.sql_query, query.success, query.execution_time_ms,
                query.result_rows, query.error_message, query.ai_translation_used
            ]
            writer.writerow(row)
            
    def _log_to_standard(self, query: UserQuery):
        """×¨×™×©×•× ×‘×œ×•×’ ×¨×’×™×œ (×§×¨×™× ×œ×‘× ×™ ××“×)"""
        status = "âœ…" if query.success else "âŒ"
        profession_info = f" [{query.profession}]" if query.profession else ""
        
        message = (
            f"{status} ×©××œ×”{profession_info}: '{query.user_question}' | "
            f"×¡×•×’: {query.query_type} | AI: {'×›×Ÿ' if query.ai_translation_used else '×œ×'}"
        )
        
        if query.success and query.result_rows is not None:
            message += f" | ×ª×•×¦××•×ª: {query.result_rows}"
        elif query.error_message:
            message += f" | ×©×’×™××”: {query.error_message}"
            
        self.logger.info(message)
        
    def get_daily_stats(self, date: str = None) -> Dict[str, Any]:
        """×¡×˜×˜×™×¡×˜×™×§×•×ª ×™×•××™×•×ª"""
        if date is None:
            date = datetime.now().strftime('%Y-%m-%d')
            
        queries = self.load_queries_by_date(date)
        
        if not queries:
            return {"date": date, "total_queries": 0}
            
        stats = {
            "date": date,
            "total_queries": len(queries),
            "successful_queries": sum(1 for q in queries if q.get('success', False)),
            "ai_translations": sum(1 for q in queries if q.get('ai_translation_used', False)),
            "professions": {},
            "query_types": {},
            "most_common_questions": {},
            "avg_execution_time": 0,
            "total_results": sum(q.get('result_rows', 0) or 0 for q in queries)
        }
        
        # × ×™×ª×•×— ×œ×¤×™ ××§×¦×•×¢×•×ª
        for query in queries:
            prof = query.get('profession', '×œ× ××•×’×“×¨')
            stats["professions"][prof] = stats["professions"].get(prof, 0) + 1
            
        # × ×™×ª×•×— ×œ×¤×™ ×¡×•×’×™ ×©××œ×•×ª
        for query in queries:
            q_type = query.get('query_type', '×œ× ××•×’×“×¨')
            stats["query_types"][q_type] = stats["query_types"].get(q_type, 0) + 1
            
        # ×©××œ×•×ª × ×¤×•×¦×•×ª
        questions = [q.get('user_question', '') for q in queries]
        for question in questions:
            if len(question) > 10:  # ×¨×§ ×©××œ×•×ª ×××™×ª×™×•×ª
                stats["most_common_questions"][question] = stats["most_common_questions"].get(question, 0) + 1
                
        # ×–××Ÿ ×‘×™×¦×•×¢ ×××•×¦×¢
        execution_times = [q.get('execution_time_ms') for q in queries if q.get('execution_time_ms')]
        if execution_times:
            stats["avg_execution_time"] = sum(execution_times) / len(execution_times)
            
        return stats
        
    def load_queries_by_date(self, date: str) -> List[Dict]:
        """×˜×¢×™× ×ª ×©××œ×•×ª ×œ×¤×™ ×ª××¨×™×š"""
        queries = []
        
        if not self.json_log_file.exists():
            return queries
            
        try:
            with open(self.json_log_file, 'r', encoding='utf-8') as f:
                for line in f:
                    if line.strip():
                        query = json.loads(line)
                        query_date = query.get('timestamp', '')[:10]  # YYYY-MM-DD
                        if query_date == date:
                            queries.append(query)
        except Exception as e:
            self.logger.error(f"×©×’×™××” ×‘×˜×¢×™× ×ª ×©××œ×•×ª: {e}")
            
        return queries
        
    def generate_analytics_report(self, days: int = 7) -> str:
        """×™×¦×™×¨×ª ×“×•×— × ×™×ª×•×— ×œ×ª×§×•×¤×”"""
        report = ["ğŸ” ×“×•×— × ×™×ª×•×— ×©××œ×•×ª ××©×ª××©×™×", "=" * 50]
        
        from datetime import timedelta
        end_date = datetime.now()
        
        total_queries = 0
        total_successes = 0
        profession_stats = {}
        
        for i in range(days):
            current_date = (end_date - timedelta(days=i)).strftime('%Y-%m-%d')
            daily_stats = self.get_daily_stats(current_date)
            
            if daily_stats["total_queries"] > 0:
                total_queries += daily_stats["total_queries"]
                total_successes += daily_stats.get("successful_queries", 0)
                
                report.append(f"\nğŸ“… {current_date}:")
                report.append(f"   ğŸ¯ ×¡×”\"×› ×©××œ×•×ª: {daily_stats['total_queries']}")
                report.append(f"   âœ… ×”×¦×œ×™×—×•: {daily_stats.get('successful_queries', 0)}")
                report.append(f"   ğŸ¤– AI: {daily_stats.get('ai_translations', 0)}")
                
                # ×¦×‘×™×¨×ª ×¡×˜×˜×™×¡×˜×™×§×•×ª ××§×¦×•×¢×•×ª
                for prof, count in daily_stats.get("professions", {}).items():
                    profession_stats[prof] = profession_stats.get(prof, 0) + count
                    
        # ×¡×™×›×•× ×›×œ×œ×™
        success_rate = (total_successes / total_queries * 100) if total_queries > 0 else 0
        
        report.extend([
            "\n" + "=" * 50,
            "ğŸ“Š ×¡×™×›×•× ×›×œ×œ×™:",
            f"ğŸ¯ ×¡×”\"×› ×©××œ×•×ª: {total_queries}",
            f"âœ… ××—×•×– ×”×¦×œ×—×”: {success_rate:.1f}%",
            f"ğŸ‘¥ ××§×¦×•×¢×•×ª ×¤×¢×™×œ×™×: {len(profession_stats)}",
            "\nğŸ“ˆ ×¤×™×œ×•×— ×œ×¤×™ ××§×¦×•×¢×•×ª:"
        ])
        
        for prof, count in sorted(profession_stats.items(), key=lambda x: x[1], reverse=True):
            percentage = (count / total_queries * 100) if total_queries > 0 else 0
            report.append(f"   {prof}: {count} ({percentage:.1f}%)")
            
        return "\n".join(report)
        
    def export_data(self, output_format: str = "excel", days: int = 30) -> str:
        """×™×™×¦×•× × ×ª×•× ×™× ×œ×¤×•×¨××˜×™× ×©×•× ×™×"""
        from datetime import timedelta
        
        # ××™×¡×•×£ × ×ª×•× ×™×
        end_date = datetime.now()
        all_queries = []
        
        for i in range(days):
            current_date = (end_date - timedelta(days=i)).strftime('%Y-%m-%d')
            daily_queries = self.load_queries_by_date(current_date)
            all_queries.extend(daily_queries)
            
        if not all_queries:
            return "âŒ ×œ× × ××¦××• × ×ª×•× ×™× ×œ×™×™×¦×•×"
            
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        
        if output_format.lower() == "excel":
            # ×™×™×¦×•× ×œ-Excel
            try:
                import pandas as pd
                
                df = pd.DataFrame(all_queries)
                output_file = self.log_dir / f"query_analytics_{timestamp}.xlsx"
                df.to_excel(output_file, index=False)
                
                return f"âœ… ×™×™×¦×•× ×œ-Excel: {output_file}"
                
            except ImportError:
                return "âŒ pandas ×œ× ××•×ª×§×Ÿ - ×œ× × ×™×ª×Ÿ ×œ×™×™×¦× ×œ-Excel"
                
        elif output_format.lower() == "json":
            # ×™×™×¦×•× ×œ-JSON
            output_file = self.log_dir / f"query_analytics_{timestamp}.json"
            
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(all_queries, f, ensure_ascii=False, indent=2)
                
            return f"âœ… ×™×™×¦×•× ×œ-JSON: {output_file}"
            
        else:
            return f"âŒ ×¤×•×¨××˜ ×œ× × ×ª××š: {output_format}"

# Global logger instance
query_logger = IFCQueryLogger()

def log_user_question(
    user_question: str,
    profession: str = None,
    category: str = None,
    query_type: str = "free_chat",
    sql_query: str = None,
    success: bool = True,
    execution_time_ms: float = None,
    result_rows: int = None,
    error_message: str = None,
    ai_translation_used: bool = False,
    session_id: str = None
):
    """×¤×•× ×§×¦×™×” × ×•×—×” ×œ×¨×™×©×•× ×©××œ×ª ××©×ª××©"""
    
    if session_id is None:
        session_id = f"session_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        
    query = UserQuery(
        timestamp=datetime.now().isoformat(),
        session_id=session_id,
        user_question=user_question,
        profession=profession,
        category=category,
        query_type=query_type,
        sql_query=sql_query,
        success=success,
        execution_time_ms=execution_time_ms,
        result_rows=result_rows,
        error_message=error_message,
        ai_translation_used=ai_translation_used,
        user_agent=None,  # ×™×›×•×œ ×œ×”×™×•×ª ××•×’×“×¨ ×-Streamlit
        ip_address=None   # ×™×›×•×œ ×œ×”×™×•×ª ××•×’×“×¨ ×-Streamlit
    )
    
    query_logger.log_query(query)